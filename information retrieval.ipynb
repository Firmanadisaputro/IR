{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "#############################################################################################\n",
      "DATASET\n",
      "#############################################################################################\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from scipy.sparse import find\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "\n",
    "def vectorizeTokens(uniqueTokens, tokens):\n",
    "    vector = []\n",
    "    for token in uniqueTokens:\n",
    "        jumlah = 0\n",
    "        for actualToken in tokens:\n",
    "            if actualToken == token:\n",
    "                jumlah += 1\n",
    "        vector.append(jumlah)\n",
    "    return vector\n",
    "\n",
    "\n",
    "#############################################################################################\n",
    "print(\"\\n\\n\")\n",
    "print(\"#############################################################################################\")    \n",
    "print(\"DATASET\")\n",
    "print(\"#############################################################################################\")    \n",
    "print(\"\\n\\n\")\n",
    "############################################################################################# \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                potongan  lirik  lagu         ekspresi lagu\n",
      "0   Pernah sakit tapi tak pernah sesakit ini Karen...       sedih dan galau\n",
      "1   Aku ingin semua cintamu hanya untukku Memang k...       sedih dan galau\n",
      "2   Baru kusadari cintaku bertepuk sebelah tangan ...       sedih dan galau\n",
      "3   Semoga aku akan memahami sisi hatimu yang beku...       sedih dan galau\n",
      "4   Semua tak mampu hilangkan cinta Yang telah kau...       sedih dan galau\n",
      "5   Biarlah ku simpan, sampai nanti aku kan ada di...       sedih dan galau\n",
      "6   Lihat aku sayang Yang sudah berjuang Menunggum...       sedih dan galau\n",
      "7   Mencoba bertahan sekuat hati Layaknya karang y...       sedih dan galau\n",
      "8   Dan kuberharap semua ini Bukanlah kekeliruan s...       sedih dan galau\n",
      "9   Aku tak bisa memiliki Menjaga cintamu Walau se...       sedih dan galau\n",
      "10  Waktu terus berlalu Tanpa kusadari yang ada ha...       sedih dan galau\n",
      "11  mana janji manismu mencintaiku sampai mati kin...       sedih dan galau\n",
      "12  Menjelang hari bahagiamu Kau tak pernah tahu a...       sedih dan galau\n",
      "13  Mudah saja bagimu Mudah saja untukmu Coba saja...       sedih dan galau\n",
      "14  Hanya tangis diri  Tak tertahankan  Tetesan ai...       sedih dan galau\n",
      "15  Selamat tinggal kasih, ku telah pergi, selaman...       sedih dan galau\n",
      "16  Pernah kucoba menyisihkan Namun hati tak rela ...       sedih dan galau\n",
      "17  Kau tlah pergi  Tinggalkan maaf yang tak teruc...       sedih dan galau\n",
      "18  Kau yang tlah pergi  Saat-saat terakhir  Ku te...       sedih dan galau\n",
      "19  Buka kita buka hari yang baru sebagai semangat...  semangat dan bahagia\n",
      "20  Aku pasti bisa Menikmati semua dan menghadapin...  semangat dan bahagia\n",
      "21  eperti pedih yang telah kita bagi Layaknya luk...  semangat dan bahagia\n",
      "22  Kawan, lihat ke depan, tunjukan jalan bagi kit...  semangat dan bahagia\n",
      "23  Marilah kita mensyukuri Semua berkat dalam hid...  semangat dan bahagia\n",
      "24  Nikmati dan lukiskan memori Kita bahagia Kita ...  semangat dan bahagia\n",
      "25  Jika memang adanya (Jika memang adanya) aku da...  semangat dan bahagia\n",
      "26  Di sini tempat cari senang Salah tempat kalo k...  semangat dan bahagia\n",
      "27  Berlari dan terus bernyanyi Mengikuti irama sa...  semangat dan bahagia\n",
      "28  Sesungguhnya perjuangan sudah dimulai Sebelum ...  semangat dan bahagia\n",
      "29  Jabat erat tanganku kawan, kau tak akan pernah...  semangat dan bahagia\n",
      "30  Percayalah Lelah ini hanya sebentar saja Janga...  semangat dan bahagia\n",
      "31  Hadapi dengan senyuman, semua yg terjadi biar ...  semangat dan bahagia\n",
      "32  Kemenangan adalah milik Orang-orang yang berdo...  semangat dan bahagia\n",
      "33  Biar saja ku tak seharum bunga mawar Tapi slal...  semangat dan bahagia\n",
      "34  Lupakan semua yang membuatmu menangis yakinkan...  semangat dan bahagia\n",
      "35  Tapakilah jejak diri, wujudkanlah mimpi.. dan ...  semangat dan bahagia\n",
      "36  Jangan kau jadikan satu kenangan yang memiluka...  semangat dan bahagia\n",
      "37  Mari berlari meraih mimpi, menggapai langit yg...  semangat dan bahagia\n",
      "38  Mari semua kita bersatu jangan ragu tuk melang...  semangat dan bahagia \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# LOAD DATASET FROM CSV\n",
    "csv_data = pd.read_csv('E:/STIKI/SEMESTER 6/INFORMATION RETRIEVAL/project/data set lirik.csv', delimiter = ',')\n",
    "print(csv_data, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATASET UNIQUE WORDS :\n",
      " ['abadi', 'ada', 'adalah', 'adanya', 'agar', 'air', 'akan', 'aku', 'akui', 'arti', 'ba', 'bagi', 'bagimu', 'bahagia', 'bahagiamu', 'baik', 'banyak', 'baru', 'begitu', 'beku', 'belaka', 'berani', 'berdiri', 'berdoa', 'berdua', 'beri', 'berikan', 'berjuang', 'berkat', 'berlalu', 'berlari', 'bermakna', 'bernyanyi', 'berpacu', 'bersama', 'bersatu', 'bersedih', 'bertahan', 'bertepuk', 'biar', 'biarlah', 'bila', 'bisa', 'buai', 'buat', 'buka', 'bukanlah', 'bunga', 'campakkan', 'cari', 'ceria', 'cerita', 'cinta', 'cintaku', 'cintamu', 'coba', 'dalam', 'dan', 'dari', 'datang', 'dendam', 'dengan', 'depan', 'di', 'didada', 'dihempas', 'dilahirkan', 'dimulai', 'diri', 'dirimu', 'doa', 'engkau', 'eperti', 'erat', 'gia', 'ha', 'hadapi', 'hancurkan', 'hangatnya', 'hanya', 'hapuslah', 'harapan', 'hari', 'hati', 'hatiku', 'hatimu', 'hidup', 'hidupku', 'hilangkan', 'hingga', 'huo', 'ia', 'ingatlah', 'ingin', 'ini', 'irama', 'itulah', 'jabat', 'jadi', 'jadikan', 'jadikanlah', 'jadilah', 'jalan', 'jalani', 'jangan', 'janganlah', 'janji', 'janjiku', 'jatuh', 'jejak', 'jelas', 'jika', 'jiwa', 'kalo', 'kamu', 'kan', 'karang', 'karena', 'kasih', 'kau', 'kaupun', 'kawan', 'ke', 'keajaiban', 'kedamaian', 'kekeliruan', 'kembali', 'kemenangan', 'kemenangkan', 'kenangan', 'kenyataan', 'kibarkan', 'kini', 'kita', 'kreativitas', 'ku', 'kuatkan', 'kuberharap', 'kucoba', 'kukira', 'kusadari', 'lagi', 'lain', 'lakukanlah', 'lalu', 'langit', 'langkah', 'layaknya', 'lebih', 'lelah', 'lewatkan', 'lihat', 'luka', 'lukaku', 'lukamu', 'lukiskan', 'lupakan', 'maaf', 'maju', 'mampu', 'mana', 'manismu', 'manusia', 'mari', 'marilah', 'masih', 'mata', 'matamu', 'mati', 'mau', 'mawar', 'melangkah', 'melompat', 'memahami', 'memang', 'membuatmu', 'memiliki', 'memilikimu', 'memilukan', 'memori', 'menangis', 'mencintai', 'mencintaiku', 'mencintaimu', 'mencoba', 'mengganti', 'menggapai', 'menghadapinya', 'mengharumkanmu', 'mengikuti', 'mengindahkanmu', 'menikmati', 'menjadi', 'menjaga', 'menjelang', 'menjemputmu', 'mensyukuri', 'mentari', 'menunggumu', 'menyerah', 'menyisihkan', 'meraih', 'meraihnya', 'milik', 'mimpi', 'mu', 'mudah', 'mungkin', 'murni', 'namun', 'nanti', 'nikmati', 'ombak', 'orang', 'pasti', 'pedih', 'pemenang', 'penuh', 'percayalah', 'pergi', 'pergulatan', 'perjuangan', 'pernah', 'pribadi', 'pulang', 'pun', 'ragu', 'raih', 'rasa', 'rela', 'remuk', 'saat', 'saja', 'sakit', 'salah', 'sampai', 'sana', 'sang', 'satu', 'sayang', 'sebagai', 'sebelah', 'sebelum', 'sebentar', 'sebuah', 'sedalam', 'seelok', 'seharum', 'sejati', 'sekuat', 'selalu', 'selamanya', 'selamat', 'semangat', 'semangatmu', 'semoga', 'semua', 'senang', 'sendiri', 'senyum', 'senyuman', 'senyummu', 'seperti', 'serahkan', 'sesakit', 'sesungguhnya', 'seumur', 'siap', 'simpan', 'sini', 'sisi', 'slalu', 'sluruh', 'sore', 'suara', 'sudah', 'tahu', 'tak', 'takdir', 'takkan', 'tangan', 'tanganku', 'tangis', 'tanpa', 'tapakilah', 'tapi', 'tegaskan', 'telah', 'teman', 'tempat', 'tenang', 'tenanglah', 'terakhir', 'terangi', 'terbaik', 'terbayang', 'terbentang', 'teringat', 'terjadi', 'terlihat', 'terluka', 'terobati', 'terpuruk', 'tersimpan', 'tertahankan', 'tertawa', 'terucap', 'terus', 'teruskan', 'tetaplah', 'tetesan', 'tinggal', 'tinggalkan', 'tinggi', 'tlah', 'tuk', 'tulus', 'tunjukan', 'uang', 'untuk', 'untukku', 'untukmu', 'waktu', 'walau', 'walaupun', 'wujudkanlah', 'yakin', 'yakinkan', 'yakinlah', 'yang', 'yeiyeah', 'yg'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# CONVERT DATA CSV as ARRAYS\n",
    "csv_data = np.array(csv_data)\n",
    "\n",
    "\n",
    "# ARRAYS CLASSIFICATION by COLUMN\n",
    "list_desc = []\n",
    "list_expression_name = []\n",
    "\n",
    "for index, v in enumerate(csv_data):\n",
    "    ## append(): push data into array\n",
    "    list_desc.append(csv_data[index][0])\n",
    "    list_expression_name.append(csv_data[index][1])\n",
    "   \n",
    "     \n",
    "#print(\"List song Desc : \\n\", list_desc, \"\\n\")\n",
    "#print(\"List expression Name : \\n\", list_expression_name, \"\\n\")\n",
    "#print(\"\\n---------------------------------\\n\")\n",
    "\n",
    "# CONVERT DATASET INTO TFIDF -> CALCULATE -> COLLECT UNIQUE WORDS\n",
    "vectorizer = TfidfVectorizer()\n",
    "vektor_dataset = vectorizer.fit_transform(list_desc)\n",
    "unique_tokens_dataset = vectorizer.get_feature_names()\n",
    "print(\"DATASET UNIQUE WORDS :\\n\", unique_tokens_dataset, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VECTOR DATASET TO ARRAY :\n",
      " [[0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.14704136 0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.         0.         0.         ... 0.10976747 0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.20699859]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# CONVERT VECTOR DATASET INTO ARRAY\n",
    "vektor_dataset_to_array = vektor_dataset.toarray()\n",
    "print(\"VECTOR DATASET TO ARRAY :\\n\", vektor_dataset_to_array, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "#############################################################################################\n",
      "SENTENCE INPUT\n",
      "#############################################################################################\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None, var_smoothing=1e-09)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RESULT BY WORD \n",
    "# for indexArtikel, v in enumerate(list_desc):\n",
    "#     print (\"Article ke\", indexArtikel, \":\", list_desc[indexArtikel])\n",
    "#     for indexKata, kata in enumerate(vectorizer.get_feature_names()):\n",
    "#         print(\"   \", indexKata, \")\", kata, vektor_dataset_to_array[indexArtikel][indexKata])\n",
    "#     print()\n",
    "    \n",
    "\n",
    "#############################################################################################\n",
    "print(\"\\n\\n\")\n",
    "print(\"#############################################################################################\")   \n",
    "print(\"SENTENCE INPUT\")\n",
    "print(\"#############################################################################################\")    \n",
    "print(\"\\n\\n\")\n",
    "#############################################################################################    \n",
    "   \n",
    "    \n",
    "gnb = GaussianNB()\n",
    "gnb.fit(vektor_dataset_to_array, list_expression_name)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SENTENCE INPUT :\n",
      " aku semangat sekali \n",
      "\n",
      "SENTENCE UNIQUE WORDS :\n",
      " ['aku', 'sekali', 'semangat'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SENTENCES INPUT\n",
    "sentence = \"aku semangat sekali\"\n",
    "print(\"SENTENCE INPUT :\\n\", sentence, \"\\n\")\n",
    "\n",
    "vektor_sentence = vectorizer.fit_transform([sentence])\n",
    "unique_tokens_sentence = vectorizer.get_feature_names();\n",
    "print(\"SENTENCE UNIQUE WORDS :\\n\", unique_tokens_sentence, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VECTOR SENTENCE TO ARRAY :\n",
      " [[0.57735027 0.57735027 0.57735027]] \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "#############################################################################################\n",
      "CALCULATE\n",
      "#############################################################################################\n",
      "\n",
      "\n",
      "\n",
      "VECTORIZE TOKENS :\n",
      " [[0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]] \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "#############################################################################################\n",
      "PREDICTION RESULT\n",
      "#############################################################################################\n",
      "\n",
      "\n",
      "\n",
      "PREDICTION :\n",
      " semangat dan bahagia \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# CONVERT VECTOR SENTENCE INTO ARRAY\n",
    "vektor_sentence_to_array = vektor_sentence.toarray()\n",
    "print(\"VECTOR SENTENCE TO ARRAY :\\n\", vektor_sentence_to_array, \"\\n\")\n",
    "\n",
    "\n",
    "#############################################################################################\n",
    "print(\"\\n\\n\")\n",
    "print(\"#############################################################################################\")    \n",
    "print(\"CALCULATE\")\n",
    "print(\"#############################################################################################\")    \n",
    "print(\"\\n\\n\")\n",
    "############################################################################################# \n",
    "\n",
    "\n",
    "vectorTest = vectorizeTokens(unique_tokens_dataset, unique_tokens_sentence)\n",
    "print(\"VECTORIZE TOKENS :\\n\", [vectorTest], \"\\n\")\n",
    "\n",
    "\n",
    "#############################################################################################\n",
    "print(\"\\n\\n\")\n",
    "print(\"#############################################################################################\")    \n",
    "print(\"PREDICTION RESULT\")\n",
    "print(\"#############################################################################################\")    \n",
    "print(\"\\n\\n\")\n",
    "############################################################################################# \n",
    "\n",
    "\n",
    "prediction = gnb.predict([vectorTest])\n",
    "print(\"PREDICTION :\\n\", prediction[0], \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
